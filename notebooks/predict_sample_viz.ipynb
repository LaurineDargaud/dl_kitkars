{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from src.models.unet import UNet\n",
    "\n",
    "from src.visualization.visualization_fct import mask_to_rgb\n",
    "\n",
    "import cv2\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "# CONSTANTS\n",
    "\n",
    "path = '../data/to_infer/'\n",
    "path_result=path+'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 5\n",
      "[PosixPath('/work3/s212803/dl_kitkars/notebooks/../data/to_infer/1_a.png'), PosixPath('/work3/s212803/dl_kitkars/notebooks/../data/to_infer/0_a.png'), PosixPath('/work3/s212803/dl_kitkars/notebooks/../data/to_infer/33_a.png'), PosixPath('/work3/s212803/dl_kitkars/notebooks/../data/to_infer/3_a.png'), PosixPath('/work3/s212803/dl_kitkars/notebooks/../data/to_infer/KitKars.jpg')]\n"
     ]
    }
   ],
   "source": [
    "# read image in target folder\n",
    "all_paths = [ Path(p).absolute() for p in glob2.glob(path + '*.png') ]\n",
    "all_paths = all_paths+[ Path(p).absolute() for p in glob2.glob(path + '*.jpg') ]\n",
    "print('Number of files:', len(all_paths))\n",
    "print(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "name_model = 'expFinal_epoch500'\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = UNet(n_channels=3, n_classes=9)\n",
    "model.load_state_dict(torch.load(f'../models/unet_finetuned_{name_model}.pt', map_location=torch.device('cpu')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work3/s212803/dl_kitkars/notebooks/../data/to_infer/1_a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:08<04:33, 68.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work3/s212803/dl_kitkars/notebooks/../data/to_infer/0_a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:14<03:22, 67.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work3/s212803/dl_kitkars/notebooks/../data/to_infer/33_a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:20<02:12, 66.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work3/s212803/dl_kitkars/notebooks/../data/to_infer/3_a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [04:26<01:06, 66.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work3/s212803/dl_kitkars/notebooks/../data/to_infer/KitKars.jpg\n"
     ]
    }
   ],
   "source": [
    "for aPath in tqdm(all_paths):\n",
    "    print(aPath)\n",
    "    rgb_img_raw = cv2.imread(str(aPath))\n",
    "    rgb_img_raw = rgb_img_raw[:, :, [2, 1, 0]]\n",
    "    rgb_img = np.transpose(rgb_img_raw, (2, 0, 1))\n",
    "\n",
    "    rgb_img = torch.Tensor(rgb_img).type(torch.float)\n",
    "    rgb_img = Normalize((127.5,127.5,127.5), (127.5,127.5,127.5)).forward(rgb_img)\n",
    "    output = model(rgb_img.view([1]+list(np.array(rgb_img.size()))))[0]\n",
    "    predictions = np.argmax(output.detach().numpy(), axis=0)\n",
    "    alpha_array = np.argwhere(predictions==0)\n",
    "    predicted_mask_img = mask_to_rgb(predictions)\n",
    "\n",
    "    for aPosition in alpha_array:\n",
    "        predicted_mask_img[aPosition[0] ,aPosition[1], :] = rgb_img_raw[aPosition[0] ,aPosition[1], :]\n",
    "    \n",
    "    # save img\n",
    "    predicted_mask_img_bgr = predicted_mask_img[:, :, [2, 1, 0]]\n",
    "    cv2.imwrite(path_result+aPath.stem+'.png', predicted_mask_img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz\n",
    "plt.title('Our prediction')\n",
    "plt.imshow(predicted_mask_img)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b436ce4aa9a050b3c12f13399e5d5f02b520991d83a91cd5126888583b80ec2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
